{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "from IPython.display import Markdown, display\n",
    "from lxml import etree\n",
    "import openai\n",
    "import json\n",
    "import re\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_completion_content(content):\n",
    "    display(Markdown(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        xml_content = file.read()\n",
    "    root = etree.fromstring(xml_content)\n",
    "    for bpmndi_tag in root.xpath(\".//bpmndi:*\", namespaces={'bpmndi': 'http://www.omg.org/spec/BPMN/20100524/DI'}):\n",
    "        parent = bpmndi_tag.getparent()\n",
    "        if parent is not None:\n",
    "            parent.remove(bpmndi_tag)\n",
    "    modified_xml = etree.tostring(root, pretty_print=True, encoding='unicode')\n",
    "    return modified_xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure OpenAI client\n",
    "client = openai.Client(api_key=\"Your OPENAI API Key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base directories and filenames\n",
    "Model = \"PaperModel.bpmnml\"\n",
    "Patter_Jsonl =\"All_Conflcit_Patterns.jsonl\"\n",
    "Prompt =\"Prompt.txt\"\n",
    "output_base_folder = \"EVAL_Results\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = pre_process(Model)\n",
    "Counter = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  50%|█████     | 1/2 [00:13<00:13, 13.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 LLM time : 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 2/2 [00:32<00:00, 16.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 LLM time : 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with open(Patter_Jsonl, 'r', encoding='utf-8') as file:\n",
    "    lines = file.readlines()\n",
    "     \n",
    "    for line_number, line in tqdm.tqdm(enumerate(lines, start=1), total=len(lines), desc=\"Processing\"):\n",
    "        # for line_number, line in enumerate(file, start=1):\n",
    "        data = json.loads(line.strip())\n",
    "        filename = data.get('filename', None)  # Fallback to 'Unknown' if the key is missing\n",
    "        XML_Contents = data.get('XML_Contents', None)\n",
    "        \n",
    "        # Load the default prompt\n",
    "        with open(Prompt, 'r') as file:\n",
    "            default_system_prompt = file.read()\n",
    "        \n",
    "        default_prompt = f\"{default_system_prompt}\\nConflict Pattern Name: {filename}\\nConflict Pattern: {XML_Contents}\\nModel: {Model}\"\n",
    "\n",
    "        user_prompt = '''\n",
    "        Is there a conflict detected based on the criteria described in the provided XML content?If so, explain what the conflict means for the use case, including which requirement is conflicting and why it is a conflict, and suggest a resolution.\n",
    "        '''\n",
    "        messages = [{\"role\": \"system\", \"content\": default_prompt}, {\"role\": \"user\", \"content\": user_prompt}]\n",
    "\n",
    "        llm_start_time = time.time()  # LLM call start time\n",
    "        \n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=messages\n",
    "        )\n",
    "        llm_end_time = time.time()  # LLM call end time\n",
    "\n",
    "        completion_content = completion.choices[0].message.content\n",
    "        llm_response_time = round(llm_end_time - llm_start_time)\n",
    "\n",
    "        #writting each api chat compeltion to a File \n",
    "        output_name = str(Counter)+ \".txt\"\n",
    "        output_name = os.path.join(output_base_folder, output_name)\n",
    "\n",
    "        try:\n",
    "            with open(output_name, \"w\") as file:\n",
    "                completion_content = f\"File Name: {output_name}\\n Pattern ID :{Counter}\\nPattern Name: {filename}\\n{completion_content}\\nLLM Response Time: {str(llm_response_time)}\"\n",
    "                # Encoding to 'utf-8' and decoding with 'ignore' to remove unknown Unicode characters\n",
    "                safe_content = completion_content.encode('utf-8', 'ignore').decode('utf-8')\n",
    "                file.write(safe_content)\n",
    "        except Exception as error:  # Using 'error' instead of 'e' as the variable name\n",
    "            print(f\"An error occurred while writing to the file: {error}\")\n",
    "\n",
    "        print(str(Counter)+\" LLM time : \" + str(llm_response_time))\n",
    "\n",
    "        Counter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.41800093650818\n"
     ]
    }
   ],
   "source": [
    "end_time = time.time()\n",
    "total_runtime = end_time - start_time\n",
    "\n",
    "print(total_runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(round(total_runtime/60))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
